import pandas as pd
import numpy as np
import os

from dataloaders.dataloader_base import BASE_DATA

# ========================================       MotionSense_HAR_DATA               =============================
class MotionSense_HAR_DATA(BASE_DATA):
    """
    MotionSense Dataset
    https://github.com/mmalekzadeh/motion-sense

    Brief Description of the Dataset:
    ---------------------------------

    This dataset includes time-series data generated by accelerometer and gyroscope sensors 
    (attitude, gravity, userAcceleration, and rotationRate). 
    It is collected with an iPhone 6s kept in the participant's front pocket using SensingKit 
    which collects information from Core Motion framework on iOS devices. 
    All data collected in 50Hz sample rate.

    A total of 24 participants in a range of gender, age, weight, and height  
    performed 6 activities in 15 trials in the same environment and conditions: 

        downstairs, upstairs, walking, jogging, sitting, and standing.

    With this dataset, we aim to look for personal attributes fingerprints in time-series of sensor data, 
    i.e. attribute-specific patterns that can be used to infer gender or personality of the data subjects in addition to their activities.


    There three different folders. Usually, you just need the folder (A) (DeviceMotion), 
    because this folder includes everything that can be captured by both Accelerometer and Gyroscope. 

    DeviceMotion_data
    This folder contains time-series collected by both Accelerometer and Gyroscope for all 15 trials.

    Thus, we have time-series with 12 features:

            attitude.roll
            attitude.pitch
            attitude.yaw
            gravity.x
            gravity.y
            gravity.z
            rotationRate.x
            rotationRate.y
            rotationRate.z
            userAcceleration.x
            userAcceleration.y
            userAcceleration.z


    Labels
        There are 6 different labels:

            dws: downstairs
            ups: upstairs
            sit: sitting
            std: standing
            wlk: walking
            jog: jogging
    """

    def __init__(self, args):

        """
        root_path : Root directory of the data set
        difference (bool) : Whether to calculate the first order derivative of the original data
        datanorm_type (str) : Methods of data normalization: "standardization", "minmax" , "per_sample_std", "per_sample_minmax"
        
        spectrogram (bool): Whether to convert raw data into frequency representations
            scales : Depends on the sampling frequency of the data （ UCI 数据的采样频率？？）
            wavelet : Methods of wavelet transformation

        """

        self.used_cols = []  # no use , use the all columns, 
        self.col_names = []  # the original files have column name

        self.label_map = [(0, 'dws'), # downstairs
                          (1, "ups"), # upstairs
                          (2, "sit"), # sitting
                          (3, "std"), # standing
                          (4, "wlk"), # walking
                          (5, "jog"), # jogging
                         ] 
        self.drop_activities = []

        # TODO , There all in total 25 subjects !
        # The original train test is ## We consider long trials as training dataset and short trials as test dataset
        # The use trial to do the train test split

        self.train_keys   = [1,2,3,4,5,7,8,9,10,11,13,14,15,16,17,19,20,21,22,23] # 5,11,17,23
        self.vali_keys    = []
        self.test_keys    = [6,12,18,24]

        self.exp_mode     = args.exp_mode
        self.down_sample:bool  \
                          = args.down_sample
        
        if self.exp_mode == "LOCV":
            self.split_tag = "sub"
        else:
            self.split_tag = "sub"
        
        self.all_keys   = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24]
        self.LOCV_keys  = [list(elem) for elem in np.array_split(self.all_keys,5)]
        self.sub_ids_of_each_sub = {}

        self.file_encoding = {}  # no use 
        

        self.labelToId = {int(x[0]): i for i, x in enumerate(self.label_map)}
        self.all_labels = list(range(len(self.label_map)))

        self.drop_activities = [self.labelToId[i] for i in self.drop_activities]
        self.no_drop_activites = [item for item in self.all_labels if item not in self.drop_activities]

        super(MotionSense_HAR_DATA, self).__init__(args)

    def load_all_the_data(self, root_path):
        print(" ----------------------- load all the data -------------------")

        trial_codes = {"dws":[1,2,11], "ups":[3,4,12], "wlk":[7,8,15], "jog":[9,16], "sit":[5,13], "std":[6,14]}    

        df_dict = {}

        for sub in range(1,25):

            for act in ('dws', 'ups', 'wlk', 'jog', 'sit', 'std'):
	
                for trial in trial_codes[act]:

                    fname = os.path.join(root_path,'A_DeviceMotion_data/'+act+'_'+str(trial)+'/sub_'+str(int(sub))+'.csv')
                    sub_data = pd.read_csv(fname)
                    sub_data = sub_data.drop(['Unnamed: 0'], axis=1)

                    sub_data["activity_id"] = act

                    sub_id = "{}_{}_{}".format(sub,act,trial)
                    sub_data["sub_id"] = sub_id
                    sub_data["sub"]    = sub

                    df_dict[sub_id] = sub_data

                    if self.split_tag != 'sub':
                        if trial > 10:
                            self.test_keys.append(sub_id)
                        else:
                            self.train_keys.append(sub_id)

                    if sub not in self.sub_ids_of_each_sub.keys():
                        self.sub_ids_of_each_sub[sub] = []
                    self.sub_ids_of_each_sub[sub].append(sub_id)

        df_all = pd.concat(df_dict)
        
        if self.down_sample:
            # Downsampling! form 50hz to 30hz
            df_all.reset_index(drop=True,inplace=True)
            index_list = list( np.arange(0,df_all.shape[0],5/3).astype(int) )
            df_all = df_all.iloc[index_list]

        df_all = df_all.set_index('sub_id')

        label_mapping = {item[1]:item[0] for item in self.label_map}
        # because the activity label in the df is not encoded, thet are  'dws', 'ups', 'wlk', 'jog', 'sit', 'std'
        # first, map them in to nummeric number
        df_all["activity_id"] = df_all["activity_id"].map(label_mapping)
        df_all["activity_id"] = df_all["activity_id"].map(self.labelToId)

        # reorder the columns as sensor1, sensor2... sensorn, sub, activity_id
        df_all = df_all[list(df_all.columns[:-2])+["sub"]+["activity_id"]]

        data_y = df_all.iloc[:,-1]
        data_x = df_all.iloc[:,:-1]
        # drop partial sensors for special task.
        # data_x = df_all.drop(columns=['attitude.roll', 'attitude.pitch', 'attitude.yaw', 'rotationRate.x', 'rotationRate.y', 'rotationRate.z'])
        # data_x = data_x.loc[:, ['userAcceleration.x', 'userAcceleration.y'  ,'userAcceleration.z', 'gravity.x' , 'gravity.y' , 'gravity.z'  ,  'sub' ]]
        # acc, gra
        data_x = data_x.reset_index()
        # sub_id, sensor1, sensor2... sensorn, sub, 
        return data_x, data_y
